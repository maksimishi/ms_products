import json
from pathlib import Path
from typing import Dict, List, Tuple
import re

from config import MAPPING_FILE, LOW_PRIORITY_CATS

# -------- 1. –∑–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–ù–í–≠–î ‚Üí {cat_id: name} ----------------
def load_mapping() -> Dict[str, Dict[int, str]]:
    p = Path(MAPPING_FILE)
    if not p.exists():
        raise FileNotFoundError(f"–§–∞–π–ª –º–∞–ø–ø–∏–Ω–≥–∞ {p} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    with p.open(encoding="utf-8") as f:
        raw = json.load(f)
    # conv cat_id -> int –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    return {k: {int(cid): name for cid, name in v.items()} for k, v in raw.items()}


_MAPPING = load_mapping()


# -------- 2. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è ----------------------------------
def normalize_text(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    text = text.lower().strip()
    # –ó–∞–º–µ–Ω—è–µ–º –¥–µ—Ñ–∏—Å—ã –∏ –¥—Ä—É–≥–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'[-_/\\]', ' ', text)
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text)
    return text


def tokenize(text: str) -> set:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∑–Ω–∞—á–∏–º—ã–µ —Ç–æ–∫–µ–Ω—ã"""
    normalized = normalize_text(text)
    # –ë–∞–∑–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã - —Å–ª–æ–≤–∞
    tokens = set(normalized.split())
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –±–µ–∑ –æ–∫–æ–Ω—á–∞–Ω–∏–π (–ø—Ä–æ—Å—Ç–∞—è —Å—Ç–µ–º–º–∏–Ω–≥)
    stemmed = set()
    for token in tokens:
        if len(token) > 3:
            # –£–±–∏—Ä–∞–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è
            if token.endswith(('—ã', '–∏', '–∞', '—è', '–æ–≤', '–µ–≤')):
                stemmed.add(token[:-1])
            if token.endswith(('–∏–π', '—ã–π', '–æ–π', '–∞—è', '—è—è', '–æ–µ', '–µ–µ')):
                stemmed.add(token[:-2])
            if token.endswith(('–∞–º–∏', '—è–º–∏', '–∫–∞—Ö', '—å—è—Ö')):
                stemmed.add(token[:-3])
    
    tokens.update(stemmed)
    return tokens


# -------- 3. –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ----------------------------
def calculate_match_score(query_tokens: set, category_name: str, cat_id: int) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–µ–ø–µ–Ω—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    category_tokens = tokenize(category_name)
    
    # –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
    exact_matches = len(query_tokens & category_tokens)
    
    # –ß–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–ø–æ–¥—Å—Ç—Ä–æ–∫–∏)
    partial_matches = 0
    for q_token in query_tokens:
        for c_token in category_tokens:
            if len(q_token) >= 3 and len(c_token) >= 3:
                if q_token in c_token or c_token in q_token:
                    partial_matches += 0.5
    
    # –û–±—â–∏–π —Å—á—ë—Ç
    total_score = exact_matches + partial_matches
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    category_lower = category_name.lower()
    query_str = ' '.join(query_tokens)
    
    # –ï—Å–ª–∏ –∏—â–µ–º "–±—Ä—é–∫–∏", –Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç "—é–±–∫–∏" - —Å–Ω–∏–∂–∞–µ–º score
    if '–±—Ä—é–∫' in query_str and '—é–±–∫' in category_lower:
        total_score *= 0.3  # –°–∏–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
    
    # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ - –ø–æ–≤—ã—à–∞–µ–º score
    if cat_id == 30683 and '–±—Ä—é–∫' in query_str:  # –ë—Ä—é–∫–∏, –±—Ä–∏–¥–∂–∏, —à–æ—Ä—Ç—ã
        total_score *= 2
    elif cat_id == 30685 and '—é–±–∫' in query_str and '–±—Ä—é–∫' not in query_str:  # –Æ–±–∫–∏
        total_score *= 2
    elif cat_id == 238944 and ('–±–ª—É–∑' in query_str or '–±–ª—É–∂' in query_str):  # –ë–ª—É–∑–∫–∏ (–∞–∫—Ç–∏–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è)
        total_score *= 3  # –°–∏–ª—å–Ω–æ –ø–æ–≤—ã—à–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è –∞–∫—Ç–∏–≤–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–ª—É–∑–æ–∫
    elif cat_id == 30686 and ('–±–ª—É–∑' in query_str or '–±–ª—É–∂' in query_str):  # –°—Ç–∞—Ä–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –±–ª—É–∑–æ–∫
        total_score *= 0.5  # –°–Ω–∏–∂–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ
    if len(query_tokens) > 0:
        normalized_score = total_score / len(query_tokens)
    else:
        normalized_score = 0
    
    return normalized_score


# –î–æ–±–∞–≤–∏–º —Å–ø–∏—Å–æ–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
INACTIVE_CATEGORIES = {
    30686,  # –†—É–±–∞—à–∫–∏, –±–ª—É–∑–∫–∏, –±–ª—É–∑—ã –∏ –±–ª—É–∑–æ–Ω—ã - –ù–ï–ê–ö–¢–ò–í–ù–ê
}

def choose_category(tnved: str, product_type: str | None = None) -> int | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π cat_id –ª–∏–±–æ None, –µ—Å–ª–∏ –¢–ù–í–≠–î –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –º–∞–ø–ø–∏–Ω–≥–µ
    """
    cats = _mapping_for(tnved)
    if not cats:
        return None
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    active_cats = {cid: name for cid, name in cats.items() if cid not in INACTIVE_CATEGORIES}
    
    # –ï—Å–ª–∏ –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
    if not active_cats:
        print(f"‚ö†Ô∏è  –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –¢–ù –í–≠–î {tnved} –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã!")
        active_cats = cats
    
    # –ï—Å–ª–∏ product_type –Ω–µ —É–∫–∞–∑–∞–Ω ‚Üí –±–µ—Ä—ë–º –ø–µ—Ä–≤—É—é –ù–ï low-priority –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö
    if not product_type:
        return _first_normal_or_any(active_cats)
    
    # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
    query_tokens = tokenize(product_type)
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    scored_cats = []
    for cat_id, cat_name in active_cats.items():
        score = calculate_match_score(query_tokens, cat_name, cat_id)
        if score > 0:
            scored_cats.append((cat_id, cat_name, score))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é score
    scored_cats.sort(key=lambda x: x[2], reverse=True)
    
    # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥
    if scored_cats:
        print(f"   üîç –ü–æ–∏—Å–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è '{product_type}':")
        for cat_id, cat_name, score in scored_cats[:3]:  # –¢–æ–ø-3
            priority_mark = " (low-priority)" if cat_id in LOW_PRIORITY_CATS else ""
            inactive_mark = " (–ù–ï–ê–ö–¢–ò–í–ù–ê!)" if cat_id in INACTIVE_CATEGORIES else ""
            print(f"      - {cat_id}: {cat_name} (score: {score:.2f}){priority_mark}{inactive_mark}")
    
    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç —Å —É—á—ë—Ç–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Å—Ä–µ–¥–∏ –ù–ï low-priority –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    for cat_id, cat_name, score in scored_cats:
        if cat_id not in LOW_PRIORITY_CATS and score > 0:
            return cat_id
    
    # –ï—Å–ª–∏ –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã low-priority, –±–µ—Ä—ë–º —Å –ª—É—á—à–∏–º score
    if scored_cats and scored_cats[0][2] > 0:
        return scored_cats[0][0]
    
    # Fallback: –ø–µ—Ä–≤–∞—è –ù–ï low-priority –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö
    return _first_normal_or_any(active_cats)


# -------- helpers ----------------------------------------------------------
def _mapping_for(tnved: str) -> Dict[int, str]:
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–¥, –ø–æ—Ç–æ–º –≥—Ä—É–ø–ø—É (–ø–µ—Ä–≤—ã–µ 4 —Ü–∏—Ñ—Ä—ã)
    return _MAPPING.get(tnved) or _MAPPING.get(tnved[:4]) or {}


def _first_normal_or_any(cats: Dict[int, str]) -> int:
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –ù–ï low-priority
    for cid in cats:
        if cid not in LOW_PRIORITY_CATS and cid not in INACTIVE_CATEGORIES:
            return cid
    
    # –ü–æ—Ç–æ–º –∞–∫—Ç–∏–≤–Ω—ã–µ low-priority
    for cid in cats:
        if cid not in INACTIVE_CATEGORIES:
            return cid
    
    # –ï—Å–ª–∏ –≤—Å–µ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã - –±–µ—Ä—ë–º –ø–µ—Ä–≤—É—é (–Ω–æ —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞!)
    if cats:
        print(f"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –í—ã–±—Ä–∞–Ω–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è {next(iter(cats))}")
        return next(iter(cats))
    
    return None


# -------- –¢–µ—Å—Ç—ã (–º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ) -----------------------------
if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    test_cases = [
        ("6204631800", "–±—Ä—é–∫–∏"),
        ("6204631800", "—é–±–∫–∞"),
        ("6204631800", "–∫—É—Ä—Ç–∫–∞"),
        ("6204631800", "–ø–∏–¥–∂–∞–∫"),
        ("6204631800", "—Ö–∞–ª–∞—Ç"),
        ("6204631800", "—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π –∫–æ—Å—Ç—é–º"),
        ("6204631800", "–¥–∂–µ–º–ø–µ—Ä"),
        ("6204631800", "—à—Ç–∞–Ω—ã —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ"),
    ]
    
    for tnved, product_type in test_cases:
        cat_id = choose_category(tnved, product_type)
        print(f"\n‚úÖ {product_type} ‚Üí –∫–∞—Ç–µ–≥–æ—Ä–∏—è {cat_id}")
        print("-" * 50)